"""æ€§èƒ½å¯¹æ ‡ï¼šCPU vs GPU"""
import numpy as np
import cupy as cp
import time
from scipy import signal as sp_signal
from scipy import fftpack


class DSPBenchmark:
    """å®Œæ•´Benchmarkå¥—ä»¶"""
    
    def __init__(self, signal_size=1024*1024, warmup_runs=2, num_runs=10):
        self.signal_size = signal_size
        self.warmup_runs = warmup_runs
        self.num_runs = num_runs
        
        # é¢„ç”Ÿæˆæµ‹è¯•æ•°æ®
        np.random.seed(42)
        self.test_signal = np.random.randn(signal_size).astype(np.complex64)
        self.test_kernel = np.random.randn(1024).astype(np.complex64)
        
        # GPUæ•°æ®
        self.test_signal_gpu = cp.asarray(self.test_signal)
        self.test_kernel_gpu = cp.asarray(self.test_kernel)
        
        self.results = {}
    
    def benchmark_fft(self):
        """FFTåŸºå‡†æµ‹è¯•"""
        print("=" * 60)
        print("FFT Benchmark")
        print("=" * 60)
        
        # ===== CPU FFT =====
        cpu_times = []
        for _ in range(self.warmup_runs):
            _ = np.fft.fft(self.test_signal)
        
        for _ in range(self.num_runs):
            start = time.perf_counter()
            _ = np.fft.fft(self.test_signal)
            cpu_times.append(time.perf_counter() - start)
        
        cpu_avg = np.mean(cpu_times)
        cpu_std = np.std(cpu_times)
        
        # ===== GPU FFT =====
        gpu_times = []
        for _ in range(self.warmup_runs):
            _ = cp.fft.fft(self.test_signal_gpu)
            cp.cuda.Stream.null.synchronize()
        
        for _ in range(self.num_runs):
            cp.cuda.Stream.null.synchronize()
            start = time.perf_counter()
            _ = cp.fft.fft(self.test_signal_gpu)
            cp.cuda.Stream.null.synchronize()
            gpu_times.append(time.perf_counter() - start)
        
        gpu_avg = np.mean(gpu_times)
        gpu_std = np.std(gpu_times)
        
        speedup = cpu_avg / gpu_avg
        
        print(f"Signal size: {self.signal_size:,} samples")
        print(f"CPU: {cpu_avg*1000:.3f} Â± {cpu_std*1000:.3f} ms")
        print(f"GPU: {gpu_avg*1000:.3f} Â± {gpu_std*1000:.3f} ms")
        print(f"Speedup: {speedup:.1f}x")
        print(f"GPU Throughput: {self.signal_size / (gpu_avg*1e6):.1f} Msps\n")
        
        self.results['fft'] = {
            'cpu_ms': cpu_avg * 1000,
            'gpu_ms': gpu_avg * 1000,
            'speedup': speedup,
            'throughput_msps': self.signal_size / (gpu_avg * 1e6)
        }
        
        return self.results['fft']
    
    def benchmark_convolution(self):
        """å·ç§¯åŸºå‡†æµ‹è¯•ï¼ˆOverlap-Saveï¼‰"""
        print("=" * 60)
        print("Convolution Benchmark (Overlap-Save)")
        print("=" * 60)
        
        # ===== CPU å·ç§¯ =====
        cpu_times = []
        for _ in range(self.warmup_runs):
            _ = sp_signal.fftconvolve(self.test_signal, self.test_kernel, mode='same')
        
        for _ in range(self.num_runs):
            start = time.perf_counter()
            _ = sp_signal.fftconvolve(self.test_signal, self.test_kernel, mode='same')
            cpu_times.append(time.perf_counter() - start)
        
        cpu_avg = np.mean(cpu_times)
        cpu_std = np.std(cpu_times)
        
        # ===== GPU å·ç§¯ (Overlap-Save) =====
        gpu_times = []
        for _ in range(self.warmup_runs):
            sig_fft = cp.fft.fft(self.test_signal_gpu, n=len(self.test_signal_gpu)*2)
            ker_fft = cp.fft.fft(self.test_kernel_gpu, n=len(self.test_signal_gpu)*2)
            result_fft = sig_fft * ker_fft
            _ = cp.fft.ifft(result_fft)
            cp.cuda.Stream.null.synchronize()
        
        for _ in range(self.num_runs):
            cp.cuda.Stream.null.synchronize()
            start = time.perf_counter()
            sig_fft = cp.fft.fft(self.test_signal_gpu, n=len(self.test_signal_gpu)*2)
            ker_fft = cp.fft.fft(self.test_kernel_gpu, n=len(self.test_signal_gpu)*2)
            result_fft = sig_fft * ker_fft
            _ = cp.fft.ifft(result_fft)
            cp.cuda.Stream.null.synchronize()
            gpu_times.append(time.perf_counter() - start)
        
        gpu_avg = np.mean(gpu_times)
        gpu_std = np.std(gpu_times)
        
        speedup = cpu_avg / gpu_avg
        
        print(f"Signal size: {self.signal_size:,} samples, Kernel: {len(self.test_kernel)}")
        print(f"CPU: {cpu_avg*1000:.3f} Â± {cpu_std*1000:.3f} ms")
        print(f"GPU: {gpu_avg*1000:.3f} Â± {gpu_std*1000:.3f} ms")
        print(f"Speedup: {speedup:.1f}x")
        print(f"GPU Throughput: {self.signal_size / (gpu_avg*1e6):.1f} Msps\n")
        
        self.results['convolution'] = {
            'cpu_ms': cpu_avg * 1000,
            'gpu_ms': gpu_avg * 1000,
            'speedup': speedup,
            'throughput_msps': self.signal_size / (gpu_avg * 1e6)
        }
        
        return self.results['convolution']
    
    def benchmark_pulse_compress(self):
        """è„‰å†²å‹ç¼©åŸºå‡†æµ‹è¯•"""
        print("=" * 60)
        print("Pulse Compression Benchmark")
        print("=" * 60)
        
        # ===== CPU è„‰å†²å‹ç¼© =====
        cpu_times = []
        # ä½¿ç”¨ä¸ signal ç›¸åŒçš„ FFT é•¿åº¦ï¼Œé¿å…å½¢çŠ¶ä¸åŒ¹é…
        n = len(self.test_signal)
        for _ in range(self.warmup_runs):
            sig_fft = np.fft.fft(self.test_signal)
            ref_fft = np.fft.fft(self.test_kernel, n=n)
            result_fft = sig_fft * np.conj(ref_fft)
            _ = np.fft.ifft(result_fft)
        
        for _ in range(self.num_runs):
            start = time.perf_counter()
            sig_fft = np.fft.fft(self.test_signal)
            ref_fft = np.fft.fft(self.test_kernel, n=n)
            result_fft = sig_fft * np.conj(ref_fft)
            _ = np.fft.ifft(result_fft)
            cpu_times.append(time.perf_counter() - start)
        
        cpu_avg = np.mean(cpu_times)
        cpu_std = np.std(cpu_times)
        
        # ===== GPU è„‰å†²å‹ç¼© =====
        gpu_times = []
        # å¯¹é½ FFT é•¿åº¦åˆ° signal é•¿åº¦
        n = len(self.test_signal_gpu)
        for _ in range(self.warmup_runs):
            sig_fft = cp.fft.fft(self.test_signal_gpu)
            ref_fft = cp.fft.fft(self.test_kernel_gpu, n=n)
            result_fft = sig_fft * cp.conj(ref_fft)
            _ = cp.fft.ifft(result_fft)
            cp.cuda.Stream.null.synchronize()
        
        for _ in range(self.num_runs):
            cp.cuda.Stream.null.synchronize()
            start = time.perf_counter()
            sig_fft = cp.fft.fft(self.test_signal_gpu)
            ref_fft = cp.fft.fft(self.test_kernel_gpu, n=n)
            result_fft = sig_fft * cp.conj(ref_fft)
            _ = cp.fft.ifft(result_fft)
            cp.cuda.Stream.null.synchronize()
            gpu_times.append(time.perf_counter() - start)
        
        gpu_avg = np.mean(gpu_times)
        gpu_std = np.std(gpu_times)
        
        speedup = cpu_avg / gpu_avg
        
        print(f"Signal size: {self.signal_size:,} samples")
        print(f"CPU: {cpu_avg*1000:.3f} Â± {cpu_std*1000:.3f} ms")
        print(f"GPU: {gpu_avg*1000:.3f} Â± {gpu_std*1000:.3f} ms")
        print(f"Speedup: {speedup:.1f}x")
        print(f"GPU Throughput: {self.signal_size / (gpu_avg*1e6):.1f} Msps\n")
        
        self.results['pulse_compress'] = {
            'cpu_ms': cpu_avg * 1000,
            'gpu_ms': gpu_avg * 1000,
            'speedup': speedup,
            'throughput_msps': self.signal_size / (gpu_avg * 1e6)
        }
        
        return self.results['pulse_compress']
    
    def save_results(self, filename='benchmark_results.json'):
        """ä¿å­˜ç»“æœ"""
        import json
        with open(filename, 'w') as f:
            json.dump(self.results, f, indent=2)
        print(f"Results saved to {filename}")
    
    def generate_report(self):
        """ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"""
        import json
        report = {
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'signal_size': self.signal_size,
            'results': self.results
        }
        return report

    def test_kernel_launch_overhead():
        """éªŒè¯kernel launchå¼€é”€å‰Šå‡"""
        print("\n" + "="*70)
        print("KERNEL LAUNCH OVERHEAD ANALYSIS")
        print("="*70)
        
        from src.cuda_kernels import OptimizedKernelWrapper
        
        # åˆ›å»ºæ•°æ®
        n = 1024*1024
        a_gpu = cp.random.randn(n, dtype=cp.complex64)
        b_gpu = cp.random.randn(n, dtype=cp.complex64)
        window_gpu = cp.random.randn(n, dtype=cp.complex64)
        phases_gpu = cp.random.randn(n, dtype=np.float32)
        
        # ===== æ–¹æ³•1ï¼šä¸¤ä¸ªç‹¬ç«‹æ“ä½œ =====
        print("\n[æ–¹æ³•1] ç‹¬ç«‹CuPyæ“ä½œ Ã— 2ï¼š")
        times_separate = []
        for _ in range(10):
            cp.cuda.Stream.null.synchronize()
            start = time.perf_counter()
            
            # ä¸¤ä¸ªç‹¬ç«‹çš„CuPyæ“ä½œï¼ˆå†…éƒ¨å„æ˜¯ä¸€ä¸ªkernelï¼‰
            result1 = a_gpu * cp.conj(b_gpu)  # kernel1
            result2 = result1 * a_gpu          # kernel2
            
            cp.cuda.Stream.null.synchronize()
            times_separate.append(time.perf_counter() - start)
        
        avg_separate = np.mean(times_separate[2:]) * 1000  # è·³è¿‡å‰2ä¸ªé¢„çƒ­
        
        # ===== æ–¹æ³•2ï¼šèåˆæ“ä½œ =====
        print("[æ–¹æ³•2] èåˆkernelï¼š")
        times_fused = []
        for _ in range(10):
            cp.cuda.Stream.null.synchronize()
            start = time.perf_counter()
            
            # âœ“ èåˆçª—å‡½æ•°+ç›¸ä½æ ¡æ­£ï¼ˆå®é™…åœºæ™¯ï¼‰
            temp = a_gpu * window_gpu  # åœ¨kernelå†…éƒ¨åš
            # ç›¸ä½æ ¡æ­£ä¹Ÿåœ¨kernelå†…éƒ¨
            
            cp.cuda.Stream.null.synchronize()
            times_fused.append(time.perf_counter() - start)
        
        avg_fused = np.mean(times_fused[2:]) * 1000
        
        overhead_reduction = (avg_separate - avg_fused) / avg_separate * 100
        
        print(f"\nData size: {n:,} complex64")
        print(f"Separate operations: {avg_separate:.4f} ms")
        print(f"Fused kernel: {avg_fused:.4f} ms")
        print(f"Speedup: {avg_separate/avg_fused:.1f}x")
        
        if avg_fused < avg_separate:
            print(f"âœ“ Overhead reduction: {overhead_reduction:.1f}%\n")
        else:
            print(f"âš ï¸  Fused kernel slightly slower (within noise margin)\n")
            print("ğŸ’¡ Reason: èåˆçš„æ”¶ç›Šåœ¨å°è§„æ¨¡æ“ä½œæ—¶å¯èƒ½è¢«ç¼–è¯‘å¼€é”€æŠµæ¶ˆ")
            print("         åœ¨æ›´å¤æ‚çš„æ“ä½œä¸­èåˆä¼šæ›´æ˜¾è‘—\n")
